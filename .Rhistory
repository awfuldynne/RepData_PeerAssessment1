filter(cran, size > 100500, r_os = ="linux-gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3,5, NA, 10))
!is.na(c(3,5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id)
)
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
install.package("httr")
install.packages("httr")
library(httr)
myapp = oauth_app("github", key="05cdb947ed7fa3e0fc56", secret="18cb950830b3adcb457287aeb59a87c417786acf")
token <- oauth2.0_token(oauth_endpoints("github"), myapp)
install.packages(httpuv)
install.packages("httpuv")
token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = token)
thing <- GET("https://api.github.com/users/jtleek/repos", token)
thing <- GET("https://api.github.com/users/jtleek/repos", gtoken)
thing
myapp2 = oauth_app("github", key="05cdb947ed7fa3e0fc56", secret="18cb950830b3adcb457287aeb59a87c417786acf")
token2 <- oauth2.0_token(oauth_endpoints("github"), myapp2)
gtoken = config(token = token2)
thing <- GET("https://api.github.com/users/jtleek/repos", gtoken2)
thing <- GET("https://api.github.com/users/jtleek/repos", gtoken)
thing
myapp2 = oauth_app("github", key="05cdb947ed7fa3e0fc56", secret="af684be3959f9bbb1aaea36932a7014b8f0da19d")
token2 <- oauth2.0_token(oauth_endpoints("github"), myapp2)
gtoken = config(token = token2)
thing <- GET("https://api.github.com/users/jtleek/repos", gtoken)
thing
library(jsonlite)
str(thing)
fromJSON(thing)
json = content(thing)
json
json = jsonlite::fromJSON(toJSON(json))
json
json[1,]
names(json)
json$name
json$name == "datasharing"
json[,json$name == "datasharing"]
json[json$name == "datasharing",]
json[json$name == "datasharing",]$created_at
install.packages("sqldf")
library(sqldf )
getwd()
acs <- read.csv(file = "./getdata-data-ss06pid")
acs <- read.csv(file = "./getdata-data-ss06pid.csv")
head(acs)
sqldf("select pwgtp1 from acs where AGEP < 50")
unique(acs$AGEP)
sqldf(
"select distinct AGEP from acs")
unique(acs$AGEP)
length(unique(acs$AGEP))
?nchar
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readlines(con)
htmlCode = readLines(con)
close(con)
htmlCode
sapply(htmlCode, nchar)
lapply(htmlCode, nchar)
lapply(htmlCode, nchar)[[c(10,20,30,100)]]
lapply(htmlCode, nchar)[[10]]
lapply(htmlCode, nchar)[[20]]
lapply(htmlCode, nchar)[[30]]
lapply(htmlCode, nchar)[[100]]
?read.fwf
?read
??read
file <- read.fwf("./getdata-wksst8110.for", skip=4, widths=c(12, 7,4, 9,4, 9,4, 9,4))
head(file)
sum(file$v4)
sum(file$V4)
install.packages("Hmisc")
install.packages("plyr")
install.packages("reshape2")
?dcast
library(reshape2)
?dcast
?ave
?merge
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", destfile = "./ss06hid.csv")
file <- read.csv("./ss06hid.csv")
head(file)
agricultureLogical <- file$ACR = 3 & file$AGS = 6
agricultureLogical <- file[file$ACR = 3 & file$AGS = 6,]
agricultureLogical <- file[file$ACR == 3 & file$AGS == 6,]
which(agricultureLogical)
agricultureLogical <- file$ACR == 3 & file$AGS == 6
which(agricultureLogical)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", destfile = "./jeffHead.jpg")
?jpeg
jeff <- readJPEG("./jeffHead.jpg")
install.packages("jpeg")
jeff <- readJPEG("./jeffHead.jpg")
library(jpeg)
jeff <- readJPEG("./jeffHead.jpg")
jeff
jeff <- readJPEG("./jeffHead.jpg", native=TRUE)
dim(jeff)
r typeof(jeff)
typeof(jeff)
quantile(jeff, probs=c(.3,.8))
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", destfile = "./jeffHead.jpg", mode="wb")
jeff <- readJPEG("./jeffHead.jpg", native = TRUE)
quantile(jeff, probs=c(.3,.8))
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", destfile = "./getdata_Fdata_FGDP.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", destfile = "./getdata_data_EDSTATS_Country.csv")
gdp <- read.csv("./getdata_Fdata_FGDP.csv")
edu <- read.csv("./getdata_data_EDSTATS_Country.csv")
head(gdp, 2)
head(edu, 2)
names(gdp)
head(gdp, 10)
head(gdp$X, 10)
merged <- merge(gdp, edu, by.x="X", by.y="CountryCode",all=TRUE)
nrow(merged)
merged <- merge(gdp, edu, by.x="X", by.y="CountryCode",all=FALSE)
nrow(merged)
head(gdp, 10)
nrow(gdp)
head(gdp[3:330], 10)
head(gdp[3:330,], 10)
head(gdp[4:330,], 10)
head(gdp[5:330,], 10)
gdp_clean <- gdp[5:330,]
merged <- merge(gdp_clean, edu, by.x="X", by.y="CountryCode",all=FALSE)
nrow(merged)
library(dplyr)
merged
head(merged, 2)
gdp_clean
names(gdp_clean)
gdp_clean$X
tail(gdp_clean, 10)
tail(gdp_clean, 20)
tail(gdp_clean, 30)
tail(gdp_clean, 50)
tail(gdp_clean, 80)
tail(gdp_clean, 100)
gdp_clean <- gdp_clean[1:235,]
gdp_clean
gdp_clean[!is.na(which(gdp_clean$X)),]
gdp_clean[which(!is.na(gdp_clean$X)),]
gdp2 <- gdp_clean[which(!is.na(gdp_clean$X)),]
merged <- merge(gdp2, edu, by.x="X", by.y="CountryCode",all=FALSE)
nrow(merged)
merged$CountryCode
names(merged)
merged$X
gdp2 <- as.integer(gdp2$Gross.domestic.product.2012)
gdp2
gdp2 <- gdp_clean[which(!is.na(gdp_clean$X)),]
gdp2$Gross.domestic.product.2012 <- as.integer(gdp2$Gross.domestic.product.2012)
gdp2
gdp2 <- gdp_clean[which(!is.na(gdp_clean$X)),]
gdp2[gdp2$Gross.domestic.product.2012 = ""]
gdp2[gdp2$Gross.domestic.product.2012 == ""]
gdp2
typeof(gdp2$Gross.domestic.product.2012)
gdp2[gdp2$Gross.domestic.product.2012 >= 1 & gdp2$Gross.domestic.product.2012 <= 192,]
gdp2$Gross.domestic.product.2012 >= 1 & gdp2$Gross.domestic.product.2012 <= 192
gdp2$Gross.domestic.product.2012 <- as.integer(as.character(gdp2$Gross.domestic.product.2012))
gdp2$Gross.domestic.product.2012
gdp2[!is.na(gdp2$Gross.domestic.product.2012),]
gdp3 <- gdp2[!is.na(gdp2$Gross.domestic.product.2012),]
nrow(gdp3)
merged <- merge(gdp3, edu, by.x="X", by.y="CountryCode",all=FALSE)
nrow(merged)
names(merged)
merged <- arrange(merged, desc(Gross.domestic.product.2012))
head(merged,15)
merged <- arrange(merged, Gross.domestic.product.2012)
head(merged,15)
merged <- arrange(merged, desc(Gross.domestic.product.2012))
names(merged)
?split
m_s <- split(merged, "Income.Group")
m_S
m_Ss
m_s
head(m_s, 1)
names(m_s)
names(merged)
rename(merged, Gross.domestic.product.2012 = gdp_rank)
rename(merged, gdp_rank = Gross.domestic.product.2012)
names(merged)
merged = rename(merged, gdp_rank = Gross.domestic.product.2012)
names(merged)
unique(merged$Income.Group)
split(merged$gdp_rank, merged$Income.Group)
lapply(split(merged$gdp_rank, merged$Income.Group), mean)
cut(merged$gdp_rank, breaks=quantile(merged$gdp_rank))
?quantile
cut(merged$gdp_rank, breaks=quantile(merged$gdp_rank, probs(.2,.4,.6,.8,1)))
cut(merged$gdp_rank, breaks=quantile(merged$gdp_rank, probs = c(.2,.4,.6,.8,1)))
cut(merged$gdp_rank, breaks=quantile(merged$gdp_rank, probs = c(0,.2,.4,.6,.8)))
cut(merged$gdp_rank, breaks=quantile(merged$gdp_rank, probs = c(.2,.4,.6,.8)))
cut(merged$gdp_rank, breaks=quantile(merged$gdp_rank, probs = c(0,.2,.4,.6,.8,1)))
merged$gdp_group <- cut(merged$gdp_rank, breaks=quantile(merged$gdp_rank, probs = c(0,.2,.4,.6,.8,1)))
table(merged$gdp_group, merged$Income.Group)
getwd()
ls()
if(!file.exists("./getdata-015-project")) {dir.create("./getdata-015-project")}
?unzip
source('~/getdata-015-project/run_analysis.R')
file_url = "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(file_url, destfile = "./getdata-015-project/getdata_projectfiles_UCI_HAR_Dataset.zip")
getwd()
ls()
list.files()
clear
## 1. Merge the training and test sets into one data set
# Read in the test data set
testdata_X          = "./getdata-015-project/UCI HAR Dataset/test/X_test.txt"
testdata_subject    = "./getdata-015-project/UCI HAR Dataset/test/subject_test.txt"
testdata_X          = "./getdata-015-project/UCI HAR Dataset/test/y_test.txt"
source('~/getdata-015-project/run_analysis.R')
## 1. Merge the training and test sets into one data set
# Read in the test data set
testdata_X          = "./getdata-015-project/UCI HAR Dataset/test/X_test.txt"
testdata_subject    = "./getdata-015-project/UCI HAR Dataset/test/subject_test.txt"
testdata_y          = "./getdata-015-project/UCI HAR Dataset/test/y_test.txt"
read.table(testdata_X)
td_x <- read.table(testdata_X)
source('~/getdata-015-project/run_analysis.R')
td_subject  = read.table(testdata_subject)
td_y        = read.table(testdata_y)
dim(td_x)
dim(td_y)
head(td_y, 5)
nrow(td_x)
dim(td_subject)
head(td_subject, 5)
feature_file        = "./getdata-015-project/UCI HAR Dataset/features.txt"
feature     = read.table(feature_file)
dim(feature)
head(feature, 4)
colnames <- feature[,2]
dim(colnames)
colnames
names(td_x)
names(td_x) <- colnames
names(td_x)
head(td_x, 1)
names(td_subject) = "subject"
names(td_y) = "Activity"
cbind(td_subject, td_y, td_x)
head(cbind(td_subject, td_y, td_x),1)
activity_labels_file = "./getdata-015-project/UCI HAR Dataset/activity_labels.txt"
activity_labels = read.table(activity_labels_file)
typeof(td)
td = cbind(td_subject, td_y, td_x)
typeof(td)
as.data.frame(td)
td = as.data.frame(cbind(td_subject, td_y, td_x))
head(td,1)
names(td)
names(td) %in% c("mean()","std()")
table(names(td) %in% c("mean()","std()"))
table(names(td) %in% "mean()"
)
table(names(td)[grep("mean()", names(td)) | grep("std()", names(td)),])
grep("mean()", names(td))
grep("mean()", names(td)) | grep("std()", names(td))
grep("std()", names(td))
c(grep("std()", names(td)), grep("mean()", names(td)))
table(names(td)[c(grep("std()", names(td)), grep("mean()", names(td))),])
table(names(td)[c(grep("std()", names(td)), grep("mean()", names(td)))])
ordered(c(grep("std()", names(td)), grep("mean()", names(td))))
?ordered
order(c(grep("std()", names(td)), grep("mean()", names(td))))
typeof(c(grep("std()", names(td)), grep("mean()", names(td))))
sort(c(grep("std()", names(td)), grep("mean()", names(td))))
sort(c(grep("std()", names(td)), grep("mean()", names(td))))
sort(c(grep("std()", names(td)), grep("mean()", names(td))))
# Read in and combine the training data set
trdata_X          = "./getdata-015-project/UCI HAR Dataset/train/X_train.txt"
trdata_subject    = "./getdata-015-project/UCI HAR Dataset/train/subject_train.txt"
trdata_y          = "./getdata-015-project/UCI HAR Dataset/train/y_train.txt"
tr_x        = read.table(trdata_X)
tr_subject  = read.table(trdata_subject)
tr_y        = read.table(trdata_y)
# Bind subject and activity columns to data
tr = cbind(tr_subject, tr_y, tr_x)
dim(tr)
dim(td)
dim(rbind(tr,td))
dim(rowbind(tr,td))
?rbind
# Name training data columns
names(tr_x) = colnames
names(tr_subject) = "subject"
names(tr_y) = "activity"
tr = cbind(tr_subject, tr_y, tr_x)
dim(rowbind(tr,td))
dim(rbind(tr,td))
names(tr)
sort(c(1, 2, grep("std()", names(td)), grep("mean()", names(td))))
columns_to_keep = sort(c(1, 2, grep("std()", names(td)), grep("mean()", names(td))))
td[,columns_to_keep]
names(td[,columns_to_keep])
names(tr[,columns_to_keep])
identical(names(tr[,columns_to_keep,]),names(td[,columns_to_keep]))
names(td_x) = colnames
td = cbind(td_subject, td_y, td_x)
identical(names(tr[,columns_to_keep,]),names(td[,columns_to_keep]))
names(td_y) = "activity"
td = cbind(td_subject, td_y, td_x)
identical(names(tr[,columns_to_keep,]),names(td[,columns_to_keep]))
data = rbind(td, tr)
names(td_y)
td_y        = read.table(testdata_y)
names(td_y)
names(activity_labels)
td_y_merged   = merge(td_y, activity_labels, by.x="V1", by.y="V1")
td_y_merged
td_y_merged[,3]
td_y_merged[3]
names(td_y_merged)
td_y_merged[2]
source('~/getdata-015-project/run_analysis.R')
data <- source('~/getdata-015-project/run_analysis.R')
head(data, 5)
head(data[1,], 1)
head(data[1], 1)
names(data)
source('~/getdata-015-project/run_analysis.R')
dim(data)
head(data[1,],2)
head(data[,1],2)
head(data[,1],4)
data$activity
nrow(data$activity)
nrow(data)
nrow(td)
nrow(tr)
nrow(tr)
source('~/getdata-015-project/run_analysis.R')
source('~/getdata-015-project/run_analysis.R')
?grep
?read.table
?names
?cbind
?merge
?sort
## 1. Merge the training and test sets into one data set
# Read in feature list
feature_file        = "./getdata-015-project/UCI HAR Dataset/features.txt"
feature     = read.table(feature_file)
col_names   = feature[,2]
# Read in activity data
activity_labels_file = "./getdata-015-project/UCI HAR Dataset/activity_labels.txt"
activity_labels = read.table(activity_labels_file)
testdata_X          = "./getdata-015-project/UCI HAR Dataset/test/X_test.txt"
testdata_subject    = "./getdata-015-project/UCI HAR Dataset/test/subject_test.txt"
testdata_y          = "./getdata-015-project/UCI HAR Dataset/test/y_test.txt"
td_x        = read.table(testdata_X)
td_subject  = read.table(testdata_subject)
td_y        = read.table(testdata_y)
td_y_merged     = merge(td_y, activity_labels, by.x="V1", by.y="V1")
td_activity     = td_y_merged[2]
names(td_x) = colnames
names(td_subject) = "subject"
names(td_activity) = "activity"
names(td_x) = col_names
source('~/getdata-015-project/run_analysis.R')
?group_by
grouped_data = group_by(data, subject, activity)
head(grouped_data, 1)
col_names
names(data)[3:]
names(data)[-3:]
names(data)[-3]
colnames_to_keep = names(td)[sort(c(grep("std()", names(td)), grep("mean()", names(td))))]
colnames_to_keep
data = rbind(td[, columns_to_keep], tr[, columns_to_keep])
dim(data)
grouped_data = group_by(data, subject, activity)
names(grouped_data)
source('~/getdata-015-project/run_analysis.R')
?melt
install.packages("reshape2")
install.packages("reshape2")
library(reshape2)
?melt
melted_data = melt(data, id=c("subject", "activity"), measure.vars=colnames_to_keep)
head(melted_data, 5)
dim(melted_data)
grouped_data = group_by(melted_data, subject, activity, variable)
summary = summarize(grouped_data, average = mean()
)
summary = summarize(grouped_data, average = mean(value))
typeof(summary)
names(summary)
head(summary, 5)
?write.table
write.table(summary, file = "./tidy_data_output.txt")
getwd()
write.table(summary, file = "./getdata-015-project/tidy_data_output.txt")
write.table(summary, file = "./getdata-015-project/tidy_data_output.txt", row.names = FALSE)
require("xtable")
require("reshape2")
?require
?read.table()
?read.table
head(read.table("./getdata-015-project/tidy_data_output.txt", header = TRUE),3)
if (!require("reshape2")) install.packages("reshape2")
if (!require("dplyr")) install.packages("dplyr")
library(reshape2)
library(dplyr)
data2 <- read.table("./getdata-015-project/tidy_data_output.txt", header = TRUE),3
data2 <- read.table("./getdata-015-project/tidy_data_output.txt", header = TRUE)
view(data2)
View(data2)
View(data2)
?abline
?with
?par
library(datasets)
with(airquality, plot(Wind, Ozone))
colors()
clear
clear()
windows()
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
?lpoints
?axis
?text
?lines
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
print(p)
?print.trellis
?trellis.par.set
library(datasets)
data(airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
install.packages("ggplot2")
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(ggplot2)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies) + stats_smooth("loess")
install.packages(knitr)
install.packages("knitr")
setwd("Coursera//RepData/RepData_PeerAssessment1/")
list.files()
activity_data = read.csv("activity.csv")
View(activity_data)
activity_data = read.csv("activity.csv", header = TRUE)
na.omit(activity_data)
activity_data = read.csv("activity.csv", header = TRUE)
activity_no_na = omit.na(activity_data)
activity_no_na = na.omit(activity_data)
typeof(activity_no_na$date)
head(activity_no_na)
with(activity_no_na, aggregate(steps ~ date))
with(activity_no_na, aggregate(steps ~ date, sum))
?aggregate
with(activity_no_na, aggregate(steps ~ date, FUN = sum))
hist(daily_steps)
daily_steps = with(activity_no_na, aggregate(steps ~ date, FUN = sum))
hist(daily_steps)
?hist
?hist(daily_steps$steps)
hist(daily_steps$steps)
hist(daily_steps$steps, xlab = "Steps Taken Per Day", title = "Frequency of Steps Taken Per Day")
hist(daily_steps$steps, xlab = "Steps Taken Per Day")
hist(daily_steps$steps, xlab = "Steps Taken Per Day")
par(title = "Histogram of Total Steps Taken Per Day")
hist(daily_steps$steps, xlab = "Steps Taken Per Day", main = "Histogram of Total Steps Taken Per Day", col = "Blue")
hist(daily_steps$steps, xlab = "Steps Taken Per Day", main = "Histogram of Total Steps Taken Per Day", col = "LightBlue")
median(daily_steps$steps)
mean(daily_steps$steps)
interval_steps = with(activity_no_na, aggregate(steps ~ interval, FUN = avg))
interval_steps = with(activity_no_na, aggregate(steps ~ interval, FUN = mean))
head(interval_steps)
with(interval_steps, plot(steps ~ interval, type = "l"))
interval_steps$interval[interval_steps$steps == max(interval_steps$steps)]
interval_steps[interval_steps$steps == max(interval_steps$steps), ]
interval_steps$interval[which.max(interval_steps$steps)]
weekdays()
?weekdays
